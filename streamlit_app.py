import streamlit as st
import pandas as pd
import json
from scraper_logic import scrape_basketball_match_full_data_filtered # ImportÄƒm funcÈ›ia de scraping

# ----------------------------------------------------------------------
# âš™ï¸ CONFIGURARE PAGINÄ‚
# ----------------------------------------------------------------------
st.set_page_config(
    page_title="OddsPortal Scraper",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ----------------------------------------------------------------------
# ğŸ’¾ CACHING
# ----------------------------------------------------------------------
# Folosim caching pentru a ne asigura cÄƒ funcÈ›ia de scraping ruleazÄƒ
# o singurÄƒ datÄƒ pentru aceeaÈ™i pereche de link-uri.
@st.cache_data(show_spinner="Rulez scraping-ul... VÄƒ rog sÄƒ aÈ™teptaÈ›i (poate dura pÃ¢nÄƒ la 30 de secunde)...")
def run_scraper(ou_url, ah_url):
    """RuleazÄƒ funcÈ›ia de scraping È™i returneazÄƒ rezultatele."""
    # Apelul funcÈ›iei cu cele douÄƒ link-uri necesare
    return scrape_basketball_match_full_data_filtered(ou_url, ah_url)

# ----------------------------------------------------------------------
# ğŸ–¥ï¸ INTERFAÈšA STREAMLIT
# ----------------------------------------------------------------------

st.title("ğŸ€ OddsPortal Basketball Line Scraper (Betano)")
st.markdown("---")

st.header("URL-uri Meci (Over/Under & Asian Handicap)")

# Input-uri pentru cele douÄƒ URL-uri
ou_link = st.text_input(
    "URL Over/Under (Total) Meci:",
    placeholder="Ex: https://www.oddsportal.com/basketball/usa/nba/meci-a-meci-b-KtP8YyZj/#over-under;1"
)

ah_link = st.text_input(
    "URL Asian Handicap Meci:",
    placeholder="Ex: https://www.oddsportal.com/basketball/usa/nba/meci-a-meci-b-KtP8YyZj/#ah;1"
)

# Buton de start
if st.button("Start Scraping", type="primary"):
    if ou_link and ah_link:
        
        # 1. Rulare Scraping
        try:
            results = run_scraper(ou_link, ah_link)
        except Exception as e:
            st.error(f"Eroare neaÈ™teptatÄƒ la rularea funcÈ›iei de scraping: {e}")
            results = None

        if results:
            st.markdown("---")
            st.header(f"Rezultate pentru: **{results.get('Match', 'N/A')}**")
            
            # 2. VerificÄƒ erorile de runtime/iniÈ›ializare
            if 'Error' in results or 'Runtime_Error' in results:
                st.error("âŒ EROARE CRITICÄ‚:")
                st.json(results)
            
            # 3. Afisare Over/Under Lines
            ou_lines = results.get('Over_Under_Lines')
            if ou_lines:
                st.subheader("ğŸ“Š Linii Over/Under (Betano)")
                df_ou = pd.DataFrame(ou_lines)
                st.dataframe(df_ou, use_container_width=True)
            elif 'Error_Over_Under' in results:
                st.warning(f"âš ï¸ Eroare la OU: {results['Error_Over_Under']}")

            st.markdown("---")

            # 4. Afisare Handicap Lines
            handicap_lines = results.get('Handicap_Lines')
            if handicap_lines:
                st.subheader("ğŸ“ˆ Linii Asian Handicap (Betano)")
                df_ah = pd.DataFrame(handicap_lines)
                st.dataframe(df_ah, use_container_width=True)
            elif 'Error_Handicap' in results:
                st.warning(f"âš ï¸ Eroare la Handicap: {results['Error_Handicap']}")

            # 5. Afisare JSON brut (pentru debug)
            with st.expander("Vizualizare JSON Brut"):
                st.json(results)

    else:
        st.warning("VÄƒ rog sÄƒ introduceÈ›i ambele URL-uri pentru a continua.")

st.markdown("---")
st.caption("AsiguraÈ›i-vÄƒ cÄƒ fiÈ™ierul `scraper_logic.py` este la zi cu cele mai recente modificÄƒri.")
